
## 3.3 样本归一化

从原始样本数据值可以看到，面积、距离、价格这三个数字的数量级不同，所以损失函数形态会是椭圆形的，不利于网络参数训练收敛。根据第 2 章的经验，必须先对数据做归一化。

由于 $\mathbf x$ 数据有两个特征，所以归一化的方法要有所变化，

$$
\begin{aligned}
x_{min}&=\begin{bmatrix} \min(x_1) & \min(x_2) \end{bmatrix}\\
x_{max}&=\begin{bmatrix} \max(x_1) & \max(x_2) \end{bmatrix}
\end{aligned}
\tag{3.3.1}
$$

那么有：

$$
x_{max} - x_{min} = [\max(x_1)-\min(x_1), \max(x_2) - \min(x_2)]
\tag{3.3.2}
$$

如【代码：common.DataLoader_3.py】所示，使用了 `axis=0` 参数，这样可以分别对两列特征值做各自的归一化，互不干扰。

```python
# 归一化训练数据
def normalize_train_data(self):
    self.x_min = np.min(self.train_x, axis=0)
    self.x_max = np.max(self.train_x, axis=0)
    self.train_x = (self.train_x - self.x_min) / (self.x_max - self.x_min)
    self.y_min = np.min(self.train_y, axis=0)
    self.y_max = np.max(self.train_y, axis=0)
    self.train_y = (self.train_y - self.y_min) / (self.y_max - self.y_min)
```

这样的话，在 `self.x_min, self.x_max` 中就各含有两个值，分别是特征值 $x_1$ 和特征值 $x_2$ 的最小、最大值。

在训练时对 $y$ 值的归一化，以及在预测时对预测值的反归一化与第 2 章的规则相同，因为预测值一般都是一个标量值。
