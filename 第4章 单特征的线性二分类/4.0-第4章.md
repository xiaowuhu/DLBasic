# 第二步 用单层线性网络做分类

---

本步中包括三章。第 4 章用两个参数的神经网络解决一维特征的线性二分类问题，第 5 章用三个参数的神经网络解决二维特征的线性二分类问题，第 6 章用九个参数的神经网络解决二维特征的三分类问题。

# 第 4 章 单特征的线性二分类

【本章要点】

这是一个在一维空间内的二分类问题，问题本身并不复杂，但是引入了很多关于分类任务的新函数、新概念。其中最重要的是逻辑回归函数，即二分类函数，虽然它叫做“回归”，但实际是“分类”，可以理解为对分界线的回归。它的作用是把负无穷到正无穷内的实数压缩到 0 和 1 之间，越靠近 0 表示越接近负类，越靠近 1 表示越接近正类，通常用 0.5 做分割点。

在本问题中，理想的分界线是一条竖直线，但是由于斜率为无穷大，所以神经网络无法得到此解。如果训练过程足够充分，会得到一条有很大斜率的直线来逼近竖直分界线。

本例中的损失函数形状不是简单的碗形，而是一个峡谷形状，所以它不止有一个解，而是有很多解，这是由于二分类函数的特性所决定的。
