
## 15.4 大力出奇迹的 VGG

前面学习的 LeNet 是为单色图片设计的，但是 AlexNet 可以用于彩色图片的分类，读者可以用 AlexNet 尝试本节中的数据集 CIFAR-10，而本节中我们将会认识一下著名的 VGG 卷积网络。

### 15.4.1 认识 VGG 网络

VGG 网络由牛津大学视觉集合研究组（visual geomotry group，VGG）提出，斩获 2014 年 ImageNet 竞赛中定位任务第一名和分类任务第二名。在原论文中，作者给了 6 个不同配置的 VGG 网络，并且尝试了不同的深度（11、13、16、19层）以及是否采用 LRN 等，表 15.4.1 显示了具体配置，表 15.4.2 是各种配置的 VGG 的参数量。其中，C 和 D 的区别是在第三层后的卷积中是否使用 1×1 的卷积核（conv1）。D 和 E 是常用的网络，俗称 VGG16 和 VGG19。

表 15.4.1 各种配置的 VGG 的结构

<img src="./img/VGG_net.png" width=480>


表 15.4.2 各种配置的 VGG 的参数量

|网络配置|A,A-LRN|B|C|D|E|
|-|-|-|-|-|-|
|参数量（M）|133|133|134|138|144|

这些参数量是如何计算的呢？以 VGG13 为例，分三种：

- 卷积层参数量 = 输入通道数×卷积核高×卷积核宽×输出通道数，比如表 15.4.3 中的层号 1，3×3×3×64=1728；
- 全连接层参数量 = 输入通道数×输出通道数，比如表 15.4.3 中的层号 11，25088×4096=102760448；
- 对应的偏置参数（其实可以忽略不计）。

最后的总数与输入图片的尺寸无关，即使是输入 3×32×32 的图片，参数量也是这么大，竟然达到了 1.33 亿。当考虑到反向传播时，实际占用的内存还需要额外的内存，普通的 SGD 只需要一倍内存保存梯度，而 Adam 需要三倍内存用于反向计算：梯度结果，一阶矩估计，二阶矩估计。

表 15.4.3 VGG13 的参数量计算

|层号|类型|输入通道|高度|宽度|输出通道|权重|偏置|
|-|-|-|-|-|-|-:|-:|
|0|输入图片|3|224|224||||
|1|conv3×3|3|224|224|64|1,728|64|
|2|conv3×3|64|224|224|64|36,864|64|
||maxpool2×2|64|112|112|0|0|64|
|3|conv3×3|64|112|112|128|73,728|128|
|4|conv3×3|128|112|112|128|147,456|128|
||maxpool2×2|128|56|56|128|0|0|401,408|
|5|conv3×3|128|56|56|256|294,912|256|
|6|conv3×3|256|56|56|256|589,824|256|
||maxpool2×2|256|28|28|256|0||
|7|conv3×3|256|28|28|512|1,179,648|512|
|8|conv3×3|512|28|28|512|2,359,296|512|
||maxpool2×2|512|14|14|512|0|0|100,352|
|9|conv3×3|512|14|14|512|2,359,296|512|
|10|conv3×3|512|14|14|512|2,359,296|512|
||maxpool2×2|512|7|7|512|0|0|25,088|
|11|FC|25088|||4096|102,760,448|4096|
|12|FC|4096|||4096|16,777,216|4096|
|13|FC|4096|||1000|4,096,000|1000|
||总计(字节)|||||133,035,712|12,136|

### 15.4.2 VGG 的特点

AlexNet 的参数量为 60 M，与之相比，VGG 除了参数量大以外，还有几个特点。

- 采用连续的几个 3×3 的卷积核（conv3）代替 AlexNet 中的较大卷积核（11×11、5×5）。对于给定的感受野，采用堆积的小卷积核优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且参数更少。简单来说，在 VGG 中，使用了四个 3×3 卷积核来代替 11×11 卷积核，使用了两个 3×3 卷积核来代替 5×5 卷积核，我们曾经在 14.7 节中做过类似说明。在每次卷积时，都做 padding=1 的填充，这样得到的结果特征图尺寸与输入的特征图尺寸相同，保持分辨率不变。

- VGG 中使用 2×2 步长为 2 的最大池化，而在 AlexNet 中使用的是有重叠的最大池化。只在一组连续的卷积之后做一次池化，但是每个卷积之后要接 ReLU 激活函数。

- VGG 网络更深，五个卷积块（内含多个卷积层）+五个池化块（内含一个池化层），在 AlexNet 中只有三个，更深的网络带来了更强大的能力。

- VGG 网络更宽，在五个卷积块中，分别使用了 64、128、256、512 个输出通道，相当于全连接层中的隐层神经元个数，具有更强大的拟合能力。

- VGG 没有使用 AlexNet 中的 LRN，因为作者发现 LRN 对于网络的性能没有帮助。在目前的实现中，一般都会在卷积层加上 BN，形成 Conv-BN-ReLU 的组合。与没有 BN 层的网络相比，有 BN 层的网络性能要好。以下是 VGG 在 ImageNet 数据集上有无 BN 时的表现。所谓 Top-5 错误率就是在预测一张猫的图片时，模型输出的前五个分类类别中含有“猫”的类别时就算作正确，所以 Top-5 比 Top-1 要容易很多。

    ```
    模型        Top-1错误率      Top-5错误率
    ---------------------------------------
    VGG11/bn    30.98/26.70	    11.37/8.58
    VGG13/bn    30.07/28.54	    10.75/9.63
    VGG16/bn    28.41/26.63	     9.62/8.50
    VGG19/bn    27.62/25.76	     9.12/8.15
    ```

- 在测试阶段，把后面的全连接层变成卷积层。当原始图片不是规定的 224×224 时，卷积后输出的尺寸不是 7×7，那么在第一个全连接层设置的 7×7×512=25088 这个数值就不能用了。如果缩放测试图片到 224×224 的话，局部细节会有一些变形，这对 3×3 的小卷积核来说不友好。这个变化要求测试时的图片可以是大于 224×224 的任意尺寸。

  如图 15.4.1，比如，当测试图片为 256×256 时，经过特征提取后得到 8×8×512 的特征图0，此时我们把 25088 的全连接输入参数 $w$ 变形为 7×7×512 的卷积核（不需要重新训练），输出通道为 4096（即第二个全连接层的神经元数量），则卷积的结果为 2×2×4096；把第一个 4096 变成 (1×1×4096)×4096 的卷积，得到卷积结果为  2×2×4096；把第二个 4096 变成 (1×1×4096)×1000 的卷积，得到卷积结果为 2×2×1000；最后对 2×2×1000 做平均池化，得到 1×1×1000 的分类特征。

<img src="./img/VGG_2.png" width=680>

图 15.4.1 测试时全连接层变成卷积层

举例来说，在 (1×1×4096)×1000 的卷积核的参数等于全连接层 4096×1000 的参数，它在 2×2×4096 的特征图上做卷积时相当于权值共享，所以不需要重新训练。

### 15.4.3 训练简化的 VGG 网络

现在我们使用 VGG 网络来解决 CIFAR-10 图片分类问题。由于 VGG 有很多个版本，所以我们初步测试一下它们各自的性能。表 15.4.4 显示了不同配置下的 VGG 网络的训练和测试情况，为了公平起见，采用了相同的分类层参数和训练超参。其中：

- 超参设置：轮数 5，批量 128，优化器 Adam，初始学习率 0.01，学习率衰减每1000步降低到 0.95。为了说明问题，准确率的变化是在测试集上的结果，但是标准的做法是不允许在测试集上做这种试验的。

- 全连接分类层：使用了三层，分别为 512×1024，1024×1024，1024×10，简写为 512$\to$1024$\to$1024$\to$10。

表 15.4.4 不同配置的 VGG 网络的训练和测试情况

|网络|训练集误差|测试集误差|测试集准确率|用时(秒)|
|-|-|-|-|-|
|VGG11|0.5381|0.8807|71.02%|432|
|VGG13|0.5189|0.7211|76.78%|568|
|VGG16|0.8810|1.2251|55.60%|594|
|VGG19|0.9508|0.9817|66.08%|690|

从表 15.4.4 只能得到一个初步的认识，由于每种网络只训练了一遍，所以不能肯定地说 VGG13 一定是最好的选择或者 VGG16 就一定是最差的。从用时上看，复杂的网络肯定需要更长的时间训练。而我们仍然倾向于使用 VGG11 和 VGG13 来解决 CIFAR-10 的问题。

VGG 本来是用于处理 224×224 尺寸以上的图片的，在每一层卷积时都预先填充一圈 0，所以卷积后尺寸不变。最大池化是唯一的降维手段，经过五次池化后，特征图尺寸变为 7×7，输出通道为 512。而在我们要尝试的 CIFAR-10 数据集上，图片尺寸仅为 32×32，经过五次池化后为 1×1，即只提取出了一个特征，很尴尬，幸好有 512 个通道，所以仍然有 512 个特征供后面分类使用。每个通道如果只有一个特征值的话，那么后面的分类层搞得太复杂就没什么意义了，所以把分类层简化后我们再做一组试验，见表 15.4.5。

表 15.4.5 比较不同的分类层设计的训练效果

|网络|全连接分类层|训练集最小误差<br>(10/50轮结果)|测试集误差<br>(10/50轮结果)|测试集准确率<br>(10/50轮结果)|
|-|-|-|-|-|
|VGG11|512$\to$32$\to$10|0.5649 / 0.0335|0.6988 / 0.9947|76.70% / 82.78%|
|VGG11|512$\to$10    |0.6308 / 0.0355|0.7422 / 1.0702|74.96% / 82.67%|
|VGG13|512$\to$32$\to$10|0.4688 / 0.0008|0.6092 / 0.8002|80.37% / 85.84%|
|VGG13|512$\to$10    |0.6542 / 0.0037|0.7778 / 0.7814|73.32% / 85.17%|

这次我们只比较 VGG11 和 VGG13，把分类层中的全连接层简化为一层或两层，在与表 15.4.4 相同的超参设置下，可以看到两层（中间有 BN 和 ReLU）的效果比一层的效果要好，而 VGG13 比 VGG11 要好，而且二者都比表 15.4.4 中的三层全连接层要好。

为了更准确地衡量模型效果，表 15.4.5 还在每种配置上测试了训练 50 轮情况，普遍要比只训练 10 轮的效果好。但是到了训练的后期，VGG11 和 VGG13 两个网络的能力就区别出来了：

- 从准确率看，VGG11 在 82% 左右，而 VGG13 在 85% 左右。
- 从测试集误差上看，VGG11 在 50 轮的表现要比在 10 轮的误差大，说明已经过拟合了。VGG13 还有潜力可挖。
- 从训练集误差上看，VGG11 在 50 轮训练的误差不够小，基本上没有多余的能力了，而 VGG13 可以达到很小的值。

### 15.4.4 使用数据增强

为了达到更高的准确率（比如 > 90%），接下来我们要在 VGG13 上做更深入的研究。在表 15.4.5 的训练中已经保存好了模型，这样我们就不需要从头开始训练了。用 Pytorch 加载保存权重参数 .pth 文件后，继续使用训练 50 轮得到如下结果：

```
......
Epoch:25/50, step:100, loss_train:0.0056, lr:0.0063
Epoch:25/50, step:200, loss_train:0.0002, lr:0.0063
Epoch:25/50, step:300, loss_train:0.0026, lr:0.0063
测试集: 
Average loss: 0.8160, Accuracy: 8668/10000 (86.68%)
......
```
在第 25 轮得到了 86.68% 的准确率，从此往后就再也没得到更好的结果。观察训练集的误差`loss_train` 已经很低了，但是测试集误差要高两个数量级，说明网络过拟合了。在 9.4 节和 14.9 节都提到了数据增强问题，但 14.9 节中的数据增强比较简单，只做了左右翻转。在本例中可以使用更多的手段，如下所示：

```python
  transform=transforms.Compose([
      transforms.ToTensor(),  # [0,1] 归一化
      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
      transforms.RandomHorizontalFlip(),  # 左右翻转
      transforms.RandomRotation(15),  # 旋转15度
      transforms.RandomAffine(0, translate=(0.1,0.1)),  # 上下左右平移 10%
      transforms.RandomCrop(32, padding=4),  # 加4像素的边，然后随机剪裁回到原尺寸
  ])),
```

在上面的代码注释注释中已经说明了这些具体手段，它们都是 Random 即 50% 的概率发生，经过四次随机处理后，数据没有被修改过的概率只有 $(\frac{1}{2})^4=\frac{1}{16}$。使用这个数据集我们再次训练这个网络，得到如下结果：

```
......
Epoch:47/50, step:100, loss_train:0.1003, lr:0.0040
Epoch:47/50, step:200, loss_train:0.1188, lr:0.0040
Epoch:47/50, step:300, loss_train:0.0796, lr:0.0040
Epoch:47/50, step:391, loss_train:0.3721, lr:0.0040
测试集: 
Average loss: 0.3042, Accuracy: 9153/10000 (91.53%)
......
```

终于得到了大于 91% 的准确率。观察训练集和测试集的误差，在同一个数量级上，说明很好地解决了过拟合问题。笔者还曾经在 VGG16 上做过同样的时间，因为参数更多，所以需要会更长的时间，

### 15.4.5 使用单层全连接分类

表 15.4.5 给了我们一个启示：虽然从效果上看，512$\to$10 的单层网络要比双层网络（带激活函数）差一些，但是如果有其它手段帮忙的话，单层分类网络能不能也达到大于 90% 的准确率呢？于是笔者又做了一次尝试，首先把分类层简化成 512×10 单层全连接：

```python
    self.classifier = nn.Sequential(
        nn.Linear(512, 10),
    )
```

并依然采用数据增强手段，超参不变，在表 15.4.5 第四行的模型基础上继续进行训练 100 轮，这次得到了 89.58% 的准确率，距离 90% 还有一步之遥。所有的泛化手段都已经用到了，下面只能从优化器入手了。虽然 Adam 非常好用（不需要调整很多参数，适应性较强），但不意味着它是普遍适用的。从图 11.6.7 可以看到，即使到了最优解附近，Adam 还是在“迂回前进”。有研究表明，SGD 方法虽然在训练初期和中期收敛速度较慢，而且容易陷入局部最优解，但是到了后期微调的时候却有很好的表现。如图 15.4.2 所示。

<img src="./img/VGG_3.png" width=240>

图 15.4.2 Adam 和 SGD 的比较

所以，我们可以先使用 Adam 快速收敛到全局最优解附近，即图 15.4.2 中的竖直虚线部分，然后使用 SGD 进行微调（fine-tune），完成最后的“缓慢冲刺”。为此，在保存了使用 Adam 得到的 89.58% 准确率的模型基础上，把优化器改成如下代码：

```python
opt = torch.optim.SGD(vgg.parameters(), momentum=0.9, nesterov=True, lr=0.01, weight_decay=1e-6)
```

使用带动量 `mementum=0.9` 的 SGDM，并且使用 Nesterov 算法（临时更新参数）以及权重衰减 `weight_decay`，再次训练 100 轮，最终得到 91.99% 的准确率。这应该是使用 VGG13 在 CIFAR-10 上能得到的最好的（state of the art，SOTA）结果了。简略过程如下：

```
Epoch:90/100, step:100, loss_train:0.1153, lr:0.0071
Epoch:90/100, step:200, loss_train:0.1539, lr:0.0071
Epoch:90/100, step:300, loss_train:0.1143, lr:0.0070
Epoch:90/100, step:391, loss_train:0.2174, lr:0.0070
测试集: 
Average loss: 0.2731, Accuracy: 9199/10000 (91.99%)
```
