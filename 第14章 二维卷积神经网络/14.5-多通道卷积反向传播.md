
## 14.5 多通道卷积反向传播

因为涉及到了升维降维的操作，使得多通道的反向传播非常复杂，主要包括卷积核梯度计算和卷积层的回传梯度计算两个部分。

### 14.5.1 计算卷积核的梯度

#### 1. 示意图

由式（14.2.6）可知：

$$
d\mathbf W = \mathbf X * d\mathbf Z
$$

从【代码：H14_2_Trial.py】中可以看到反向传播代码如下：

```python
    dw = simple_conv2d(x, dz, dw)  # 反向传播
```
感觉真的是做一个简单的反向卷积就可以达到目的，但是当输入数据为 NCHW 四维时（但单样本单通道数据本身还是二维），情况会变得不那么乐观。如图 14.5.1 所示，表 14.5.1 比较了各部分的尺寸。

<img src="./img/conv2ddw.png" width=480/>

图 14.5.1 多个输入输出通道时的二维卷积计算卷积核梯度 $d\mathbf W$

#### 2. 朴素实现

表 14.5.1 各部分数据的尺寸

<img src="./img/conv2ddw_size.png" width=400/>

从表 14.5.1 可以看到，它并不满足表 14.3.1 所归纳的规则，比如 $\mathbf X$ 的批量数 8 不等于 $d\mathbf W$ 的批量数 2，这将会造成卷积计算的代码 `conv4d` 无法复用，必须重写，但是可以复用更底层的 `conv2d`。代码如下：

```python
    # 计算 dW 的梯度朴素版
    def backward_dw_simple(self, dZ):
        self.WB.dW *= 0  # 先把缓存清零, 后面要用到这个缓冲区
        for n in range(self.batch_size):            # N, 获得单样本
            for c_out in range(self.output_channel):# C_out 遍历卷积核输出通道
                weight = dZ[n, c_out]               # 按批量和输出通道取出误差值当作卷积核
                for c_in in range(self.input_channel): 
                    image = self.x[n, c_in]         # 取出一个通道的image
                    self._conv2d(image, weight,     # 调用 2d 卷积
                        self.kernel_height, self.kernel_width, 
                        self.WB.dW[c_out, c_in])    # 存放结果的 buf
        self.WB.dW /= self.batch_size               # 除以批大小
        sellf.WB.dB = np.sum(dZ, axis=(0, 2, 3)) / self.batch_size
        return self.WB.dW, self.WB.dB
```

#### 3. 转置实现

但是仔细观察表 14.5.1 中的尺寸数据，还是有章可循的：

- $\mathbf X$ 和 $d\mathbf Z$ 的 C 值应该相同，所以把它们的第一维和第二维互换，记作 $\mathbf X'、d\mathbf Z'$；

- $d\mathbf W$ 的 C 值应该和 $d\mathbf Z$ 的 N 值相同，所以把 $d\mathbf W$ 的第一维和第二维互换，记作 $d\mathbf W'$。

这样就形成表 14.5.2 所示的尺寸，这就完全符合 4d 卷积的格式了。

表 14.5.2 各部分数据的尺寸转置

<img src="./img/conv2ddw_size_t.png" width=400/>

下面是调用 `conv4d` 的代码实现：

```python
    # 用标准4d卷积但是需要先变形原始数据
    def backward_dw_transpose(self, dZ):
        × = self.x.transpose(1, 0, 2, 3)    # (C, N, H, W)
        W = dZ.transpose(1, 0, 2, 3)        # 把 dZ 看作 Weight
        B = np.zeros((W.shape[0], 1))       # (C, 1) 这个没啥用，置 0
        # 标准卷积，得到 dW 结果
        dW = self._conv_4d(                 # 调用标准的 4d 卷积完成任务
            ×, W, B, self.batch_size, self.output_channel, 
            self.WB.W.shape[2], self.WB.W.shape[3], 1)
        self.WB.dW = dW.transpose(1, 0, 2, 3)  / self.batch_size    # 转置回来 (N, C, H, W)
        self.WB.dB = np.sum(dZ, axis=(0, 2, 3)) / self.batch_size           # 按输出通道求和
        return self.WB.dW, self.WB.dB
```

#### 4. col2im 实现

在 14.4 节中讲到了 im2col 算法，把原始数据和卷积核分别展开，二者直接进行均值乘法运算。如果把这个过程反过来使用也是可以的，就如同全连接层的反向传播一样。

```python
    # 使用 im2col 的方式实现反向传播, 和线性层一样，但是前后需要转置
    def backward_dw_col2im(self, dZ):
        # 传入的误差矩阵变成二维数组
        col_dZ = np.transpose(delta_in, axes=(0,2,3,1)).reshape(-1, self.output_channel)
        # 计算 dB
        self.WB.dB = np.sum(col_dZ, axis=0, keepdims=True).T / self.batch_size
        # 按全连接层的规则计算 dW
        col_dW = np.dot(self.col_x.T, col_dZ) / self.batch_size
        # 转置、变形成原始的 dW 形状
        self.WB.dW = col_dW.T.reshape(self.output_channel, self.input_channel, 
                                      self.kernel_height, self.kernel_width)
        return self.WB.dW, self.WB.dB
```

### 14.5.2 计算卷积层的回传梯度

#### 1. 示意图

根据式（14.2.14）：

$$
d\mathbf X = d\mathbf Z^0 * \mathbf{W}^{rot180} 
$$

卷积层回传的梯度由补零的 $d\mathbf Z$ 值与转核的 $W$ 值做卷积运算得到，但是 14.5.1 节的经验告诉我们，事情没有那么简单。我们不妨画出图 14.5.2 来一起分析一下。

<img src="./img/conv2ddx.png" width=480/>

图 14.5.2 多个输入输出通道时的二维卷积计算回传梯度

把各部分的数据尺寸放到表 14.5.3 中比较。

表 14.5.3 各部分数据的尺寸

<img src="./img/conv2ddx_size.png" width=400/>

可以看到除了 $d\mathbf Z$ 的 N 和 $d\mathbf X$ 的 N 相同外，其它的两对数值都没有对应上，不能直接使用 conv4d 做卷积。但是表 14.5.2 的经验告诉我们可以通过转置来实现数据对接，如表 14.5.4 所示。

表 14.5.5 各部分数据处理后的尺寸

<img src="./img/conv2ddx_size_t.png" width=400/>

先把 $d\mathbf Z$ 做填充，变成 $d\mathbf Z^0_0$，然后需要把 $\mathbf W$ 做一次转置，从 (2,3,4,5) 变成 (3,2,4,5)，但是别忘了要反转卷积核，并非把 (4,5) 对调，而是内部元素的顺序进行反转，比如：

$$
\begin{pmatrix}
1 & 2 & 3 & 4 & 5 \\
6 & 7 & 8 & 9 & 10 \\
11 & 12 & 13 & 14 & 15 \\
16 & 17 & 18 & 19 & 20
\end{pmatrix}
\to
\begin{pmatrix}
20 & 19 & 18 & 17 & 16 \\
15 & 14 & 13 & 12 & 11 \\
10 & 9 & 8 & 7 & 6 \\
5 & 4 & 3 & 2 & 1 \\
\end{pmatrix}
$$

#### 2. 转置实现

这里给出转置实现的代码，我们就不做朴素实现了，请读者根据思考与练习中的要求自己实现。

```python
    def backward_dx_transpose(self, dZ):
        # dZ 补零
        pad_h, pad_w = self.calculate_padding_size( # 计算需要补几个 0
            self.output_height, self.output_width,  # output 做为 input
            self.kernel_height, self.kernel_width,  # kernel 做为 kernel
            self.input_height, self.input_width)    # input 做为 output
        dZ_pad = np.pad(dZ, [(0,0), (0,0), (pad_h,pad_h), (pad_w,pad_w)]) # 补 0
        # W 转置并翻转
        Weights = np.rot90(self.WB.W.transpose(1, 0, 2, 3), 2, axes=(2,3))
        B = np.zeros((Weights.shape[0], 1))         # 没用，置0
        d× = self._conv4d(dZ_pad, Weights, B,       # 4d 卷积
                     self.output_channel, self.input_channel, 
                     self.input_height, self.input_width, 1)
        return d×
```

其中的 `calculate_padding_size()` 函数，实际上是把式（14.3.1）反过来用：已知 input、output 和 kernel 的尺寸，求 padding 的尺寸。即：

$$
\begin{aligned}
H_{Padding} &= ((H_{output}-1)*Stride - H_{input} + H_{kernel})/2 \\
W_{Padding} &= ((W_{output}-1)*Stride - W_{input} + W_{kernel})/2
\end{aligned}
\tag{14.5.1}
$$


#### 3. col2im 实现

这种实现不需要考虑补 0 和 stride 不为 1 的情况，因为在把 `dZ` 展开的过程中都“自动”包含了对应位置的 0 值。

```python
    def backward_dx_col2im(self, dZ):
        # 把 dZ 变成二维矩阵
        col_dZ = np.transpose(dZ, axes=(0,2,3,1)).reshape(-1, self.output_channel)
        # self.col_w 在前向计算的时候已经保存下来了
        col_delta_out = np.dot(col_dZ, self.col_w.T)
        dX = self.col2im(  # 矩阵乘法
            col_delta_out, self.x.shape, self.kernel_height, self.kernel_width, 
            self.stride, self.padding, 
            self.output_height, self.output_width)
        return dX
```
以下是计算 `dW` 的函数：
```python
    def backward_dw_col2im(self, dZ):
        col_dZ = np.transpose(dZ, axes=(0,2,3,1)).reshape(-1, self.output_channel)
        self.WB.dB = np.sum(col_dZ, axis=0, keepdims=True).T / self.batch_size
        col_dW = np.dot(self.col_x.T, col_dZ) / self.batch_size
        self.WB.dW = col_dW.T.reshape(self.output_channel, self.input_channel, 
                                      self.kernel_height, self.kernel_width)
        return self.WB.dW, self.WB.dB
```
都实现好以后可以自行比较一下结果，两种方法的结果应该一致，并且最好和 PyTorch 的结果比较一下。注意，在计算 `dW` 的时候，PyTorch 的结果没有除以批量数，所以比较大。

### 14.5.3 性能比较【电子资源】

在 14.4 节和本节中实现了很多算法，现在做一个比较，伪代码如下：

```python
def test_function(count):
    # 创建卷积实例
    for i in range(count):  # 循环 1000 次
        # 创建输入数据 x
        # 卷积前向计算 (x)
        # 创建回传误差 dz
        # 反向传播 (dz)
```

我们分别测试 PyTorch 在 CPU 上的表现、朴素算法的表现（由于使用 Numpy 所以只支持 CPU）、im2col/col2im 算法的表现。在正式测试前先调用三种方法各一次做个热身（warm up），然后各循环 1000 次，结果如下：

```
--- 计算1000次前向 + 后向的耗时 ---
torch:  0.4572010040283203
simple: 20.58254599571228
im2col: 0.20048069953918457
```
运行【代码：H14_4_Conv_Compare.py】可以得到上述结果，但是由于读者的计算机性能可能会有细微差异。

朴素算法要慢很多，因为它只适合于用来说明卷积的前向、反向的计算原理，其内部的多重循环非常耗时。im2col/col2im 算法的表现很亮眼，竟然比 PyTorch 还要快。如果把 `test_torch()` 方法中的 `requires_grad=True` 和 `retain_graph=True` 参数去掉，运行会快三分之一左右。
