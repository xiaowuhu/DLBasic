
## 14.5 多通道卷积反向传播

### 14.5.1 计算卷积核的梯度

<img src="./img/conv2ddw.png" width=480/>

图 14.5.1 多个输入输出通道时的二维卷积计算卷积核梯度 $d\mathbf W$

表 14.5.1 各部分数据的尺寸

<img src="./img/conv2ddw_size.png" width=400/>

表 14.5.2 各部分数据的尺寸转置

<img src="./img/conv2ddw_size_t.png" width=400/>

### 14.5.2 计算卷积层的回传梯度

<img src="./img/conv2ddx.png" width=480/>

图 14.5.2 多个输入输出通道时的二维卷积计算回传梯度


表 14.5.3 各部分数据的尺寸

<img src="./img/conv2ddx_size.png" width=400/>

表 14.5.5 各部分数据处理后的尺寸

<img src="./img/conv2ddx_size_t.png" width=400/>


### 14.5.3 性能比较【电子资源】

在 14.4 节和本节中实现了很多算法，现在做一个比较，伪代码如下：

```python
def test_function(count):
    # 创建卷积实例
    for i in range(count):  # 循环 1000 次
        # 创建输入数据 x
        # 卷积前向计算 (x)
        # 创建回传误差 dz
        # 反向传播 (dz)
```

我们分别测试 PyTorch 在 CPU 上的表现、朴素算法的表现（由于使用 Numpy 所以只支持 CPU）、im2col/col2im 算法的表现。在正式测试前先调用三种方法各一次做个热身（warm up），然后各循环 1000 次，结果如下：

```
--- 计算1000次前向 + 后向的耗时 ---
torch:  0.4572010040283203
simple: 20.58254599571228
im2col: 0.20048069953918457
```
运行【代码：H14_4_Conv_Compare.py】可以得到上述结果，但是由于读者的计算机性能可能会有细微差异。

朴素算法要慢很多，因为它只适合于用来说明卷积的前向、反向的计算原理，其内部的多重循环非常耗时。im2col/col2im 算法的表现很亮眼，竟然比 PyTorch 还要快。如果把 `test_torch()` 方法中的 `requires_grad=True` 和 `retain_graph=True` 参数去掉，运行会快三分之一左右。
