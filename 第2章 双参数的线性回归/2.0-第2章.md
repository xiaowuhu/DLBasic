# 第 2 章 双参数的线性回归

【本章要点】

本章将提出一个只有两个参数的线性回归问题。

我们将会把第 1 章中学习的一元函数的梯度下降和损失函数扩展到二元函数，把单样本梯度下降扩展到多样本梯度下降，并推导出梯度下降在多样本情况下的公式。

归一化数据会使得整个神经网络的数据大体运行在 $[0,1]$ 之间，避免过大或过小，也使得损失函数的形状更利于梯度下降的进行。但是在预测时需要反归一化预测结果。
